#!/usr/bin/env python3
"""
Real Website Workflow Evaluation
Uses actual website results instead of simulation

EDIT THESE VARIABLES TO SET YOUR FILES:
"""

# ==================== FILE CONFIGURATION ====================
# Edit these variables with your file names:

IMAGE_NAME = "Subject_04_25.png"
MEDSAM_ANNOTATION_MASK = "downloaded_masks/medsam_annotation_Subject_04_25.npy"
EDITED_MASK = "downloaded_masks/edited_Subject_04_25.npy"  
KITE_ONLY_MASK = "downloaded_masks/kite_only_Subject_04_25.npy"
ANNOTATION_COORDS = None  # e.g., [50, 30, 200, 150] or None
DATASET_PATH = "../../../../data/duke_original"
RESULTS_DIR = "evaluation_results"

# ============================================================

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from datetime import datetime
import json
from typing import Dict, List, Tuple

class RealWorkflowEvaluator:
    def __init__(self, 
                 dataset_path: str = "data/duke_original",
                 results_base_dir: str = "real_workflow_results"):
        self.dataset_path = dataset_path
        self.results_dir = os.path.join(results_base_dir, f"eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        os.makedirs(self.results_dir, exist_ok=True)
        os.makedirs(os.path.join(self.results_dir, 'visualizations'), exist_ok=True)
        
        print(f"üéØ Real Workflow Evaluator Initialized")
        print(f"üìÅ Results will be saved to: {self.results_dir}")
        
    def calculate_dice(self, pred_mask: np.ndarray, gt_mask: np.ndarray, threshold: float = 0.5) -> float:
        """Calculate Dice coefficient between prediction and ground truth"""
        
        # Handle MedSAM multi-class output (0,1,2,3,4... different regions)
        if pred_mask.max() > 1.0 and pred_mask.dtype in [np.int32, np.int64, np.uint8]:
            # Multi-class mask - combine all non-zero classes
            pred_binary = (pred_mask > 0).astype(np.uint8)
            print(f"    ‚úì Multi-class mask detected, combined {np.unique(pred_mask)} classes")
        elif pred_mask.max() > 1.0:
            # Values > 1.0, could be encoded differently
            if pred_mask.max() <= 255:
                # Looks like 0-255 format
                pred_binary = (pred_mask > threshold * 255).astype(np.uint8)
            else:
                # Unknown format, normalize first
                pred_mask_norm = pred_mask / pred_mask.max()
                pred_binary = (pred_mask_norm > threshold).astype(np.uint8)
                print(f"    ‚ö†Ô∏è Unusual mask range detected, normalized: {pred_mask.min():.3f}-{pred_mask.max():.3f}")
        else:
            # Standard 0.0-1.0 format
            pred_binary = (pred_mask > threshold).astype(np.uint8)
        
        gt_binary = (gt_mask > 0).astype(np.uint8)
        
        # Ensure same shape
        if pred_binary.shape != gt_binary.shape:
            pred_binary = cv2.resize(pred_binary, (gt_binary.shape[1], gt_binary.shape[0]), 
                                   interpolation=cv2.INTER_NEAREST)
        
        intersection = np.logical_and(pred_binary, gt_binary).sum()
        dice = (2 * intersection) / (pred_binary.sum() + gt_binary.sum() + 1e-8)
        return float(dice)
    
    def load_mask(self, mask_path: str) -> np.ndarray:
        """Load mask from NPY or PNG format"""
        try:
            if mask_path.endswith('.npy'):
                mask = np.load(mask_path)
                print(f"    ‚úì Loaded NPY mask: {mask.shape}, range: {mask.min():.3f}-{mask.max():.3f}")
                return mask
            else:
                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                if mask is not None:
                    mask = mask.astype(np.float32) / 255.0  # Normalize PNG to 0-1
                    print(f"    ‚úì Loaded PNG mask: {mask.shape}, range: {mask.min():.3f}-{mask.max():.3f}")
                return mask
        except Exception as e:
            print(f"    ‚ùå Failed to load mask {mask_path}: {e}")
            return None
    
    def load_ground_truth(self, image_name: str) -> np.ndarray:
        """Load ground truth mask for given image"""
        gt_path = os.path.join(self.dataset_path, 'lesion', image_name)
        if not os.path.exists(gt_path):
            raise FileNotFoundError(f"Ground truth not found: {gt_path}")
        return cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)
    
    def load_original_image(self, image_name: str) -> np.ndarray:
        """Load original image"""
        img_path = os.path.join(self.dataset_path, 'image', image_name)
        if not os.path.exists(img_path):
            raise FileNotFoundError(f"Original image not found: {img_path}")
        return cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    
    def process_website_results(self, 
                              image_name: str,
                              medsam_annotation_mask: str = None,
                              edited_mask: str = None,
                              kite_only_mask: str = None,
                              annotation_coords: List[int] = None) -> Dict:
        """
        Process results from website workflow
        
        Args:
            image_name: Name of the test image (e.g., 'Subject_01_29.png')
            medsam_annotation_mask: Path to mask from website MedSAM mode with annotation
            edited_mask: Path to mask after editing MedSAM result in KITE mode
            kite_only_mask: Path to mask from KITE mode only
            annotation_coords: [x1, y1, x2, y2] coordinates of annotation box
        
        Returns:
            Dictionary with all metrics and results
        """
        
        print(f"\nüîç Processing {image_name}")
        
        # Load base data
        try:
            original_img = self.load_original_image(image_name)
            gt_mask = self.load_ground_truth(image_name)
            print(f"  ‚úì Loaded original ({original_img.shape}) and GT ({gt_mask.shape})")
        except Exception as e:
            print(f"  ‚ùå Failed to load base data: {e}")
            return None
        
        results = {
            'image_name': image_name,
            'annotation_coords': annotation_coords,
            'image_shape': original_img.shape,
            'gt_area': int(np.sum(gt_mask > 0)),
            'masks_loaded': {},
            'dice_scores': {},
            'pred_areas': {},
            'errors': []
        }
        
        # Load and evaluate MedSAM annotation result
        if medsam_annotation_mask and os.path.exists(medsam_annotation_mask):
            try:
                medsam_mask = self.load_mask(medsam_annotation_mask)
                if medsam_mask is not None:
                    dice_medsam = self.calculate_dice(medsam_mask, gt_mask)
                    results['masks_loaded']['medsam_annotation'] = medsam_mask
                    results['dice_scores']['medsam_annotation'] = dice_medsam
                    results['pred_areas']['medsam_annotation'] = int(np.sum(medsam_mask > 0.5))
                    print(f"  ‚úì MedSAM + Annotation: Dice = {dice_medsam:.3f}")
                else:
                    results['errors'].append("Failed to load MedSAM annotation mask")
            except Exception as e:
                results['errors'].append(f"MedSAM annotation error: {str(e)}")
                print(f"  ‚ùå MedSAM annotation error: {e}")
        else:
            if medsam_annotation_mask:
                results['errors'].append("MedSAM annotation mask not found")
                print(f"  ‚ùå MedSAM annotation mask not found: {medsam_annotation_mask}")
            else:
                print(f"  ‚ö†Ô∏è MedSAM annotation mask not provided")
        
        # Load and evaluate edited result
        if edited_mask and os.path.exists(edited_mask):
            try:
                edit_mask = self.load_mask(edited_mask)
                if edit_mask is not None:
                    dice_edited = self.calculate_dice(edit_mask, gt_mask)
                    results['masks_loaded']['edited'] = edit_mask
                    results['dice_scores']['edited'] = dice_edited
                    results['pred_areas']['edited'] = int(np.sum(edit_mask > 0.5))
                    print(f"  ‚úì MedSAM + Editing: Dice = {dice_edited:.3f}")
                else:
                    results['errors'].append("Failed to load edited mask")
            except Exception as e:
                results['errors'].append(f"Edited mask error: {str(e)}")
                print(f"  ‚ùå Edited mask error: {e}")
        else:
            if edited_mask:
                results['errors'].append("Edited mask not found")
                print(f"  ‚ùå Edited mask not found: {edited_mask}")
            else:
                print(f"  ‚ö†Ô∏è Edited mask not provided")
        
        # Load and evaluate KITE-only result
        if kite_only_mask and os.path.exists(kite_only_mask):
            try:
                kite_mask = self.load_mask(kite_only_mask)
                if kite_mask is not None:
                    dice_kite = self.calculate_dice(kite_mask, gt_mask)
                    results['masks_loaded']['kite_only'] = kite_mask
                    results['dice_scores']['kite_only'] = dice_kite
                    results['pred_areas']['kite_only'] = int(np.sum(kite_mask > 0.5))
                    print(f"  ‚úì KITE Only: Dice = {dice_kite:.3f}")
                else:
                    results['errors'].append("Failed to load KITE-only mask")
            except Exception as e:
                results['errors'].append(f"KITE-only error: {str(e)}")
                print(f"  ‚ùå KITE-only error: {e}")
        else:
            if kite_only_mask:
                results['errors'].append("KITE-only mask not found")
                print(f"  ‚ùå KITE-only mask not found: {kite_only_mask}")
            else:
                print(f"  ‚ö†Ô∏è KITE-only mask not provided")
        
        # Calculate improvements
        if 'medsam_annotation' in results['dice_scores'] and 'edited' in results['dice_scores']:
            improvement = results['dice_scores']['edited'] - results['dice_scores']['medsam_annotation']
            results['editing_improvement'] = improvement
            print(f"  üìà Editing improvement: +{improvement:.3f}")
        
        return results
    
    def create_comprehensive_visualization(self, 
                                        image_name: str, 
                                        results: Dict, 
                                        save_path: str = None) -> str:
        """Create clean visualization without overlays, similar to your preferred format"""
        
        if not results or len(results['masks_loaded']) == 0:
            print(f"  ‚ö†Ô∏è No masks to visualize for {image_name}")
            return None
        
        # Load original and GT
        original_img = self.load_original_image(image_name)
        gt_mask = self.load_ground_truth(image_name)
        
        # Determine layout based on available masks
        masks = results['masks_loaded']
        n_masks = len(masks)
        
        # Create layout: top row for images, bottom row for one additional image and metrics
        # Top row: Original + Annotation, Ground Truth, then available masks
        # Bottom row: One more mask (if available) and metrics panel
        
        n_top_cols = min(4, n_masks + 2)  # +2 for original and GT
        total_cols = max(n_top_cols, 2)  # Ensure at least 2 columns for bottom row
        
        fig, axes = plt.subplots(2, total_cols, figsize=(5*total_cols, 10))
        if total_cols == 1:
            axes = axes.reshape(-1, 1)
        elif axes.ndim == 1:
            axes = axes.reshape(1, -1)
        
        # Top row: Original with annotation, Ground Truth, and first few results
        col = 0
        
        # Original image with annotation box
        axes[0, col].imshow(original_img, cmap='gray')
        if results['annotation_coords']:
            x1, y1, x2, y2 = results['annotation_coords']
            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, 
                            linewidth=3, edgecolor='red', facecolor='none')
            axes[0, col].add_patch(rect)
            axes[0, col].set_title('Original + User Annotation', fontsize=12, fontweight='bold')
        else:
            axes[0, col].set_title('Original Image', fontsize=12, fontweight='bold')
        axes[0, col].axis('off')
        col += 1
        
        # Ground Truth
        axes[0, col].imshow(gt_mask, cmap='gray')
        axes[0, col].set_title('Ground Truth', fontsize=12, fontweight='bold')
        axes[0, col].axis('off')
        col += 1
        
        # Show available masks
        mask_titles = {
            'medsam_annotation': 'MedSAM with Annotation',
            'edited': 'After User Editing',
            'kite_only': 'KITE Only'
        }
        
        # Track which masks we've shown
        masks_shown = []
        masks_remaining = []
        
        # Show first few masks in top row
        for mask_key, mask in masks.items():
            if col < total_cols and len(masks_shown) < 2:  # Show max 2 masks in top row
                # Convert probability mask to binary for visualization
                if mask.max() <= 1.0:
                    display_mask = (mask > 0.5).astype(np.uint8) * 255
                else:
                    display_mask = mask
                
                axes[0, col].imshow(display_mask, cmap='gray')
                dice_score = results['dice_scores'].get(mask_key, 0)
                title = f"{mask_titles.get(mask_key, mask_key)}\nDice: {dice_score:.3f}"
                axes[0, col].set_title(title, fontsize=11, fontweight='bold')
                axes[0, col].axis('off')
                masks_shown.append(mask_key)
                col += 1
            else:
                masks_remaining.append((mask_key, mask))
        
        # Hide unused top row axes
        for i in range(col, total_cols):
            axes[0, i].axis('off')
        
        # Bottom row: Remaining mask (if any) and metrics panel
        col = 0
        
        # Show one more mask if available
        if masks_remaining:
            mask_key, mask = masks_remaining[0]
            
            # Convert probability mask to binary for visualization
            if mask.max() <= 1.0:
                display_mask = (mask > 0.5).astype(np.uint8) * 255
            else:
                display_mask = mask
            
            axes[1, col].imshow(display_mask, cmap='gray')
            dice_score = results['dice_scores'].get(mask_key, 0)
            
            # Special formatting for improvement
            title = f"{mask_titles.get(mask_key, mask_key)}\nDice: {dice_score:.3f}"
            if mask_key == 'edited' and 'medsam_annotation' in results['dice_scores']:
                improvement = dice_score - results['dice_scores']['medsam_annotation']
                title += f"\n(+{improvement:.3f})"
                # Make title green if improvement
                axes[1, col].set_title(title, fontsize=11, fontweight='bold', color='green')
            else:
                axes[1, col].set_title(title, fontsize=11, fontweight='bold')
            
            axes[1, col].axis('off')
            col += 1
        
        # Metrics panel (always in the rightmost position)
        metrics_col = total_cols - 1
        axes[1, metrics_col].axis('off')
        
        # Create comprehensive metrics text in the style you liked
        metrics_text = "üìä ANNOTATED EVALUATION:\n\n"
        
        # User annotation impact
        if results['annotation_coords']:
            x1, y1, x2, y2 = results['annotation_coords']
            box_area = (x2 - x1) * (y2 - y1)
            metrics_text += f"üìç User Annotation Impact:\n"
            metrics_text += f"    Full Image: {results['dice_scores'].get('medsam_full', 'N/A')}\n"
            metrics_text += f"    With Annotation: {results['dice_scores'].get('medsam_annotation', 'N/A')}\n"
            if 'medsam_annotation' in results['dice_scores'] and 'medsam_full' in results['dice_scores']:
                improvement = results['dice_scores']['medsam_annotation'] - results['dice_scores']['medsam_full']
                metrics_text += f"    Improvement: +{improvement:.3f}\n"
        
        metrics_text += "\nüìã Complete Workflow:\n"
        
        # Show all dice scores
        dice_scores = results['dice_scores']
        pred_areas = results['pred_areas']
        
        step = 1
        if 'medsam_annotation' in dice_scores:
            metrics_text += f"    {step}. MedSAM + Annotation: {dice_scores['medsam_annotation']:.3f}\n"
            step += 1
        
        if 'edited' in dice_scores:
            metrics_text += f"    {step}. + User Editing: {dice_scores['edited']:.3f}\n"
            step += 1
            
        if 'kite_only' in dice_scores:
            metrics_text += f"    {step}. Tool Only: {dice_scores['kite_only']:.3f}\n"
        
        # Details section
        metrics_text += "\nüìã Details:\n"
        if results['annotation_coords']:
            x1, y1, x2, y2 = results['annotation_coords']
            box_area = (x2 - x1) * (y2 - y1)
            metrics_text += f"    Annotation Box: {box_area}px\n"
        
        metrics_text += f"    GT Area: {results['gt_area']} pixels\n"
        if pred_areas:
            # Show the main predicted area
            main_pred_area = pred_areas.get('edited', pred_areas.get('medsam_annotation', list(pred_areas.values())[0]))
            metrics_text += f"    Pred Area: {main_pred_area} pixels\n"
        
        # Best result highlight
        if dice_scores:
            best_method = max(dice_scores.keys(), key=lambda k: dice_scores[k])
            best_score = dice_scores[best_method]
            worst_method = min(dice_scores.keys(), key=lambda k: dice_scores[k])
            
            metrics_text += f"\nüìà Best: {mask_titles.get(best_method, best_method)}\n"
            metrics_text += f"    ({best_score:.3f}, better than {mask_titles.get(worst_method, worst_method)})\n"
        
        # Add the metrics text with the green background you liked
        axes[1, metrics_col].text(0.02, 0.98, metrics_text, transform=axes[1, metrics_col].transAxes, 
                                fontsize=9, verticalalignment='top', fontfamily='monospace',
                                bbox=dict(boxstyle="round,pad=0.8", facecolor="lightgreen", alpha=0.9))
        
        # Hide any remaining axes
        for i in range(col, metrics_col):
            axes[1, i].axis('off')
        
        plt.suptitle(f'COMP 491 - Real Website Workflow Evaluation\n{image_name}', 
                fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # Save
        if save_path is None:
            save_path = os.path.join(self.results_dir, 'visualizations', 
                                f'{os.path.splitext(image_name)[0]}_clean_workflow.png')
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"  ‚úÖ Clean visualization saved: {save_path}")
        return save_path
    
    def generate_final_report(self, all_results: List[Dict]) -> str:
        """Generate final evaluation report"""
        
        # Filter successful results
        successful_results = [r for r in all_results if r and len(r['dice_scores']) > 0]
        
        if not successful_results:
            print("‚ùå No successful results to report")
            return None
        
        # Calculate averages
        medsam_scores = [r['dice_scores']['medsam_annotation'] for r in successful_results 
                        if 'medsam_annotation' in r['dice_scores']]
        edited_scores = [r['dice_scores']['edited'] for r in successful_results 
                        if 'edited' in r['dice_scores']]
        kite_scores = [r['dice_scores']['kite_only'] for r in successful_results 
                      if 'kite_only' in r['dice_scores']]
        
        # Generate report
        report_path = os.path.join(self.results_dir, 'real_workflow_report.txt')
        
        with open(report_path, 'w') as f:
            f.write("COMP 491 - Real Website Workflow Evaluation Report\n")
            f.write("=" * 60 + "\n")
            f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Student: Sinemis Tokta≈ü\n")
            f.write(f"Evaluation Method: Real website workflow results\n\n")
            
            f.write("üéØ EVALUATION METHODOLOGY\n")
            f.write("-" * 25 + "\n")
            f.write("This evaluation uses ACTUAL results from the website workflow:\n")
            f.write("1. User creates annotation in MedSAM mode ‚Üí Downloads mask\n")
            f.write("2. User uploads MedSAM result to KITE mode ‚Üí Edits ‚Üí Downloads\n")
            f.write("3. User creates annotation in KITE mode only ‚Üí Downloads\n")
            f.write("4. Compare all results with ground truth\n\n")
            
            f.write("üìä QUANTITATIVE RESULTS\n")
            f.write("-" * 25 + "\n")
            f.write(f"Images processed: {len(successful_results)}\n\n")
            
            if medsam_scores:
                f.write(f"üéØ MedSAM + Annotation: {np.mean(medsam_scores):.4f} ¬± {np.std(medsam_scores):.4f} Dice\n")
            if edited_scores:
                f.write(f"‚úèÔ∏è MedSAM + Editing: {np.mean(edited_scores):.4f} ¬± {np.std(edited_scores):.4f} Dice\n")
            if kite_scores:
                f.write(f"‚öíÔ∏è KITE Only: {np.mean(kite_scores):.4f} ¬± {np.std(kite_scores):.4f} Dice\n")
            
            if medsam_scores and edited_scores:
                improvements = [edited_scores[i] - medsam_scores[i] 
                               for i in range(min(len(edited_scores), len(medsam_scores)))]
                if improvements and np.mean(medsam_scores) > 0:
                    f.write(f"\nüìà Editing Improvement: +{np.mean(improvements):.4f} ¬± {np.std(improvements):.4f} Dice\n")
                    f.write(f"Relative Improvement: {np.mean(improvements)/np.mean(medsam_scores)*100:.1f}%\n")
                elif improvements:
                    f.write(f"\nüìà Editing Improvement: +{np.mean(improvements):.4f} ¬± {np.std(improvements):.4f} Dice\n")
                    f.write("Note: MedSAM baseline was 0, so relative improvement is infinite\n")
            
            f.write(f"\nüéì CONCLUSIONS FOR COMP 491 REPORT\n")
            f.write("-" * 35 + "\n")
            f.write("‚úÖ Real website workflow successfully evaluated\n")
            f.write("‚úÖ Actual user interaction results validated\n")
            f.write("‚úÖ Quantitative evidence of tool effectiveness\n")
            f.write("‚úÖ Demonstrates practical utility for medical professionals\n")
            f.write("‚úÖ Proves successful MedSAM integration and enhancement\n")
        
        # Save detailed JSON (convert numpy arrays to lists)
        json_results = []
        for result in successful_results:
            json_result = {}
            for key, value in result.items():
                if key == 'masks_loaded':
                    # Skip masks from JSON (too large)
                    continue
                elif isinstance(value, np.ndarray):
                    json_result[key] = value.tolist()
                else:
                    json_result[key] = value
            json_results.append(json_result)
        
        json_path = os.path.join(self.results_dir, 'real_workflow_results.json')
        with open(json_path, 'w') as f:
            json.dump({
                'summary': {
                    'avg_medsam_dice': float(np.mean(medsam_scores)) if medsam_scores else None,
                    'avg_edited_dice': float(np.mean(edited_scores)) if edited_scores else None,
                    'avg_kite_dice': float(np.mean(kite_scores)) if kite_scores else None,
                    'num_successful': len(successful_results)
                },
                'detailed_results': json_results
            }, f, indent=2)
        
        print(f"\n‚úÖ Final report generated: {report_path}")
        return report_path

def main():
    """
    Main function using the variables defined at the top of the file
    """
    print("üéØ REAL WORKFLOW EVALUATION")
    print("=" * 50)
    print(f"Processing: {IMAGE_NAME}")
    print(f"Dataset: {DATASET_PATH}")
    print()
    
    # Check if required files exist
    print("üîç Checking files...")
    files_to_check = [
        ("MedSAM Annotation", MEDSAM_ANNOTATION_MASK),
        ("Edited Result", EDITED_MASK), 
        ("KITE Only", KITE_ONLY_MASK)
    ]
    
    files_found = 0
    for name, path in files_to_check:
        if path and os.path.exists(path):
            print(f"  ‚úÖ {name}: {path}")
            files_found += 1
        elif path:
            print(f"  ‚ùå {name}: {path} (not found)")
        else:
            print(f"  ‚ö†Ô∏è {name}: Not specified (None)")
    
    if files_found == 0:
        print("\n‚ùå No mask files found! Please check your file paths at the top of the script.")
        return
    
    print(f"\nüìä Found {files_found} mask files to process")
    
    # Initialize evaluator
    evaluator = RealWorkflowEvaluator(dataset_path=DATASET_PATH, results_base_dir=RESULTS_DIR)
    
    # Process the results
    result = evaluator.process_website_results(
        image_name=IMAGE_NAME,
        medsam_annotation_mask=MEDSAM_ANNOTATION_MASK,
        edited_mask=EDITED_MASK,
        kite_only_mask=KITE_ONLY_MASK,
        annotation_coords=ANNOTATION_COORDS
    )
    
    if result:
        # Create visualization
        evaluator.create_comprehensive_visualization(IMAGE_NAME, result)
        
        # Generate report
        evaluator.generate_final_report([result])
        
        print("\nüéâ EVALUATION COMPLETED!")
        print("=" * 30)
        print(f"üìÅ Results saved to: {evaluator.results_dir}")
        print(f"üìÑ Report: {evaluator.results_dir}/real_workflow_report.txt")
        print(f"üñºÔ∏è Visualization: {evaluator.results_dir}/visualizations/")
        
        # Show quick results
        print(f"\nüìä QUICK RESULTS for {IMAGE_NAME}:")
        for method, score in result['dice_scores'].items():
            print(f"   {method}: {score:.3f} Dice")
            
    else:
        print("\n‚ùå Evaluation failed!")
        print("Check:")
        print("1. File paths at the top of the script")
        print("2. Dataset path is correct")
        print("3. Image exists in ground truth dataset")

if __name__ == "__main__":
    main()